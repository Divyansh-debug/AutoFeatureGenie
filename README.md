# ğŸ§  AutoFeatureGenie

> **Intelligent, AI-powered feature engineering automation for tabular datasets**

AutoFeatureGenie leverages Large Language Models and semantic search to generate domain-aware feature suggestions, reducing the manual effort in feature engineering workflows while improving model performance.

---

## ğŸ¯ Problem Statement

Feature engineering is a critical but time-consuming step in machine learning pipelines. Data scientists spend **countless hours** exploring datasets, identifying patterns, and manually creating new features. This process requires deep domain expertise and is difficult to scale.

**AutoFeatureGenie solves this by**:
- ğŸ” Automating exploratory data analysis (EDA) at scale
- ğŸ¤– Generating contextually relevant feature suggestions using AI
- ğŸ“š Reducing domain knowledge dependency through intelligent recommendations
- âš™ï¸ Integrating seamlessly into existing ML workflows

---

## ğŸ—ï¸ Architecture & Workflow

```
ğŸ“¤ User Input (CSV)
    â†“
ğŸ¨ [Frontend - Streamlit]
    â†“
âš¡ [FastAPI Backend]
    â”œâ”€â”€ ğŸ“Š EDA Engine (Data Analysis & Profiling)
    â”œâ”€â”€ ğŸ”§ Feature Engine (Initial Feature Generation)
    â””â”€â”€ ğŸ§  RAG Engine (Semantic Similarity + LLM)
    â†“
ğŸ—‚ï¸ [Vector Store (FAISS) + Embeddings (Sentence Transformers)]
    â†“
âœ¨ [Google Gemini LLM]
    â†“
ğŸ“‹ Feature Suggestions (JSON)
    â†“
ğŸ¯ [Frontend - Results Display]
```

### ğŸ”‘ Key Components

| Component | Purpose |
|-----------|---------|
| **ğŸ“Š EDA Pipeline** | Analyzes dataset structure, computes statistics, identifies targets, detects missing values |
| **ğŸ”§ Feature Engine** | Extracts initial feature candidates and prepares context for LLM |
| **ğŸ§  RAG System** | Uses FAISS + Sentence Transformers to retrieve similar historical features |
| **âœ¨ LLM Integration** | Google Gemini generates context-aware, domain-specific suggestions |
| **âš¡ API Layer** | FastAPI exposes endpoints for seamless integration |

---

## ğŸ› ï¸ Tech Stack

| Layer | Technologies |
|-------|--------------|
| **ğŸ¨ Frontend** | Streamlit Â· Pandas Â· Requests |
| **âš™ï¸ Backend** | FastAPI Â· Pandas Â· Feature Engine |
| **ğŸ¤– AI/ML** | Google Generative AI (Gemini) Â· Sentence Transformers Â· FAISS Â· LangChain |
| **ğŸ³ Infrastructure** | Docker Â· Python 3.8+ |

---

## âœ¨ Features

| Feature | Description |
|---------|-------------|
| ğŸ” **Automated EDA** | Comprehensive dataset summaries with statistics, distributions, metadata |
| ğŸ¤– **AI-Powered Suggestions** | Intelligent, context-aware feature recommendations via Gemini |
| ğŸ§  **RAG Integration** | Semantic search over feature history for relevant suggestions |
| ğŸ¯ **Domain-Specific Prompts** | Customizable prompting for industry-specific engineering |
| ğŸ“‹ **JSON Output** | Structured, machine-readable feature suggestions |
| ğŸ“ˆ **Scalable Design** | Batch processing & ML pipeline integration |
| ğŸ”Œ **API-First** | RESTful endpoints for programmatic access |

---

## ğŸ“¦ Installation

### ğŸ“‹ Prerequisites
- Python 3.8+
- pip
- ğŸ”‘ Google Cloud API key for Gemini â†’ [Get it here](https://makersuite.google.com/app/apikey)

### ğŸš€ Setup

```bash
# 1ï¸âƒ£ Clone repository
git clone https://github.com/Divyansh-debug/AutoFeatureGenie.git
cd AutoFeatureGenie

# 2ï¸âƒ£ Install dependencies
pip install -r requirements.txt

# 3ï¸âƒ£ Configure environment
echo "GOOGLE_API_KEY=your-api-key-here" > .env

# 4ï¸âƒ£ Verify setup
python -c "import fastapi, streamlit, google.generativeai; print('âœ… All dependencies installed')"
```

---

## ğŸ¯ Quick Start

### âš¡ Running Backend Server

```bash
uvicorn backend.main:app --reload --host 0.0.0.0 --port 8000
```

- ğŸŒ Backend: `http://localhost:8000`
- ğŸ“š API Docs: `http://localhost:8000/docs`

### ğŸ¨ Running Frontend

```bash
streamlit run frontend/app.py
```

- ğŸŒ Frontend: `http://localhost:8501`

### ğŸ³ Docker Deployment

```bash
docker-compose -f docker/docker-compose.yml up
```

---

## ğŸ“¡ API Usage

### 1ï¸âƒ£ Generate EDA Summary

```http
POST /api/eda
```

**Request**:
```json
{
  "file_name": "customer_data.csv",
  "data": "base64_encoded_csv_content"
}
```

**Response** âœ…:
```json
{
  "summary": "Dataset contains 10,000 customer records with 15 features...",
  "columns": [
    {
      "name": "age",
      "type": "numeric",
      "missing_percent": 0.5,
      "stats": {
        "mean": 42.3,
        "std": 15.2,
        "min": 18,
        "max": 85
      }
    }
  ],
  "target": "conversion",
  "record_count": 10000
}
```

### 2ï¸âƒ£ Get Feature Suggestions

```http
POST /api/suggest-features
```

**Request**:
```json
{
  "eda_summary": "Dataset with customer data...",
  "columns": ["age", "income", "purchase_history"],
  "target": "conversion",
  "domain": "e-commerce",
  "custom_prompt": "Focus on interaction features and temporal patterns"
}
```

**Response** âœ…:
```json
{
  "features": [
    {
      "name": "age_income_ratio",
      "formula": "age / income",
      "description": "Normalized age-to-income proportion for demographic segmentation",
      "rationale": "Captures purchasing power relative to demographic age group"
    },
    {
      "name": "recency_frequency_interaction",
      "formula": "log(purchase_recency + 1) * purchase_frequency",
      "description": "Interaction between purchase recency and frequency",
      "rationale": "Identifies highly engaged recent customers"
    }
  ],
  "timestamp": "2024-01-15T10:30:00Z"
}
```

---

## ğŸ”„ Example Workflow

```
1ï¸âƒ£ Upload CSV via Streamlit interface
   â†“
2ï¸âƒ£ View EDA Summary (statistics, missing values, distributions)
   â†“
3ï¸âƒ£ Click "Get Feature Suggestions"
   â†“
4ï¸âƒ£ Review AI-generated features with explanations
   â†“
5ï¸âƒ£ Export features for model training
```

---

## ğŸ“‚ Folder Structure

```
AutoFeatureGenie/
â”œâ”€â”€ ğŸ“ backend/
â”‚   â”œâ”€â”€ main.py                 # âš¡ FastAPI entry point
â”‚   â”œâ”€â”€ rag_engine.py           # ğŸ§  FAISS + retrieval logic
â”‚   â”œâ”€â”€ feature_engine.py       # ğŸ”§ Feature generation & EDA
â”‚   â””â”€â”€ prompts.py              # ğŸ“ LLM prompt templates
â”‚
â”œâ”€â”€ ğŸ“ frontend/
â”‚   â””â”€â”€ app.py                  # ğŸ¨ Streamlit UI
â”‚
â”œâ”€â”€ ğŸ“ data/
â”‚   â””â”€â”€ sample_datasets/        # ğŸ“Š Example CSVs
â”‚
â”œâ”€â”€ ğŸ“ docker/
â”‚   â”œâ”€â”€ Dockerfile              # ğŸ³ Container config
â”‚   â””â”€â”€ docker-compose.yml      # ğŸ”— Multi-container setup
â”‚
â”œâ”€â”€ ğŸ“ domain_docs/
â”‚   â””â”€â”€ feature_patterns.md     # ğŸ“š Domain templates
â”‚
â”œâ”€â”€ ğŸ“ src/
â”‚   â””â”€â”€ utils.py                # ğŸ› ï¸ Shared utilities
â”‚
â”œâ”€â”€ ğŸ“ tests/
â”‚   â”œâ”€â”€ test_eda.py             # âœ… EDA tests
â”‚   â”œâ”€â”€ test_api.py             # âœ… API tests
â”‚   â””â”€â”€ test_rag.py             # âœ… RAG tests
â”‚
â”œâ”€â”€ requirements.txt            # ğŸ“¦ Dependencies
â”œâ”€â”€ .env.example                # ğŸ”‘ Environment template
â””â”€â”€ README.md                   # ğŸ“– This file
```

---

## âš™ï¸ Configuration

### ğŸ”‘ Environment Variables

```bash
GOOGLE_API_KEY=                 # ğŸ”´ Required: API key
FASTAPI_HOST=0.0.0.0           # API host
FASTAPI_PORT=8000              # API port
LOG_LEVEL=INFO                  # Logging level
VECTORSTORE_PATH=./vectorstore  # FAISS location
```

### ğŸ¯ Domain-Specific Customization

Edit `backend/prompts.py`:

```python
FINANCE_PROMPT = """
You are a feature engineer for financial risk modeling.
Generate features for predicting loan defaults...
"""

ECOMMERCE_PROMPT = """
You are a feature engineer for e-commerce recommendation systems.
Generate features for predicting customer churn...
"""
```

---

## ğŸš€ Future Roadmap

- ğŸ¬ **Multi-Modal Features**: Text, images, time-series support
- âš¡ **Distributed Processing**: Spark integration (100GB+ datasets)
- ğŸ“Š **Feature Ranking**: Automated importance scoring
- ğŸ”„ **Feedback Loop**: Self-improving suggestions
- ğŸ“ˆ **Version Control**: Feature evolution tracking
- ğŸ”Œ **Integrations**: Databricks, Snowflake, BigQuery connectors
- ğŸ‘ï¸ **Monitoring**: Drift detection & analytics
- ğŸ” **Explainability**: SHAP/LIME integration
- â³ **Async Jobs**: Batch processing queue
- ğŸ“ **Fine-Tuned Models**: Enterprise LLM training

---

## âœ… Testing

```bash
# ğŸ§ª Run all tests
pytest tests/ -v

# ğŸ¯ Run specific suite
pytest tests/test_api.py

# ğŸ“Š With coverage report
pytest tests/ --cov=backend --cov-report=html
```

---

## âš¡ Performance Metrics

| Operation | Time | Details |
|-----------|------|---------|
| ğŸ“Š EDA Generation | 2-5s | For 100K rows |
| ğŸ¤– Feature Suggestions | 5-10s | Includes LLM latency |
| ğŸ” Vector Search | <100ms | Similarity retrieval |
| ğŸ’¾ Memory Usage | ~500MB + 2GB | Baseline + large datasets |

---

## ğŸ¤ Contributing

We â¤ï¸ contributions! Here's how:

```bash
# 1. Fork the repo
# 2. Create feature branch
git checkout -b feature/your-awesome-feature

# 3. Commit with clear messages
git commit -m "Add awesome feature"

# 4. Push & submit PR
git push origin feature/your-awesome-feature
```

---

## ğŸ“§ Contact & Links

| | |
|--|--|
| ğŸ‘¨â€ğŸ’» **Author** | Divyansh Agarwal |
| ğŸ“§ **Email** | agarwaldivyansh4002@gmail.com |
| ğŸ”— **Repository** | [AutoFeatureGenie on GitHub](https://github.com/Divyansh-debug/AutoFeatureGenie) |

---

<div align="center">

### ğŸš€ Built for data scientists and ML engineers who want to ship models faster

**â­ If you find this useful, please star the repo!**

[Give Feedback](https://github.com/Divyansh-debug/AutoFeatureGenie/issues) Â· [Report Bug](https://github.com/Divyansh-debug/AutoFeatureGenie/issues) Â· [Request Feature](https://github.com/Divyansh-debug/AutoFeatureGenie/issues)

</div>
